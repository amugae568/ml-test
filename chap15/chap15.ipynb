{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_time_series(batch_size, n_steps):\n",
    "    freq1, freq2, offset1, offset2 = np.random.rand(4, batch_size, 1)\n",
    "    time = np.linspace(0, 1, n_steps)\n",
    "    series = 0.5 * np.sin((time - offset1) * (freq1 * 10 + 10))\n",
    "    series += 0.2 * np.sin((time - offset2) * (freq2 * 20 + 20))\n",
    "    series += 0.1 * (np.random.rand(batch_size, n_steps) - 0.5)\n",
    "    return series[..., np.newaxis].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = 50\n",
    "series = generate_time_series(10000, n_steps= + 1)\n",
    "X_train, y_train = series[:7000, :n_steps], series[:7000, -1]\n",
    "X_valid, y_valid = series[7000:9000, :n_steps], series[7000:9000, -1]\n",
    "X_test, y_test = series[9000:, :n_steps], series[9000:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 1, 1), (7000, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "y_pred = X_valid[:, -1]\n",
    "np.mean(mean_squared_error(y_valid, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 0s 655us/step - loss: 0.0016 - val_loss: 6.2026e-04\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 0s 619us/step - loss: 2.6854e-04 - val_loss: 7.6682e-05\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 0s 590us/step - loss: 2.8363e-05 - val_loss: 5.7353e-06\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 0s 583us/step - loss: 1.8290e-06 - val_loss: 2.5184e-07\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 0s 583us/step - loss: 7.0718e-08 - val_loss: 6.6978e-09\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 0s 583us/step - loss: 1.6132e-09 - val_loss: 9.4277e-11\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 0s 597us/step - loss: 2.0603e-11 - val_loss: 7.9222e-13\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 0s 612us/step - loss: 3.0215e-13 - val_loss: 2.7647e-13\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 0s 604us/step - loss: 2.7434e-13 - val_loss: 2.7680e-13\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 0s 583us/step - loss: 2.7381e-13 - val_loss: 2.7675e-13\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 0s 596us/step - loss: 2.3946e-13 - val_loss: 2.3732e-13\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 0s 612us/step - loss: 2.1392e-13 - val_loss: 2.0878e-13\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 0s 590us/step - loss: 1.8292e-13 - val_loss: 1.5123e-13\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 0s 576us/step - loss: 1.5007e-13 - val_loss: 1.5138e-13\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 0s 583us/step - loss: 1.0902e-13 - val_loss: 1.0241e-13\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 0s 583us/step - loss: 1.0149e-13 - val_loss: 1.0235e-13\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 0s 583us/step - loss: 9.4071e-14 - val_loss: 8.8879e-14\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 0s 587us/step - loss: 7.4795e-14 - val_loss: 6.4431e-14\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 0s 576us/step - loss: 6.3546e-14 - val_loss: 6.5565e-14\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=[1, 1]),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(\"adam\", \"mse\")\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=50, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 1s 1ms/step - loss: 0.0012 - val_loss: 5.0661e-04\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 0s 701us/step - loss: 3.9478e-04 - val_loss: 3.3233e-04\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 0s 640us/step - loss: 3.4067e-04 - val_loss: 3.2991e-04\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 0s 634us/step - loss: 3.3993e-04 - val_loss: 3.3069e-04\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 0s 641us/step - loss: 3.3971e-04 - val_loss: 3.3278e-04\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 0s 655us/step - loss: 3.3906e-04 - val_loss: 3.3184e-04\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 0s 640us/step - loss: 3.3979e-04 - val_loss: 3.3128e-04\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 0s 645us/step - loss: 3.3939e-04 - val_loss: 3.3640e-04\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 0s 645us/step - loss: 3.3985e-04 - val_loss: 3.3011e-04\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 0s 634us/step - loss: 3.3887e-04 - val_loss: 3.3169e-04\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 0s 626us/step - loss: 3.4008e-04 - val_loss: 3.3118e-04\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 0s 647us/step - loss: 3.3929e-04 - val_loss: 3.3026e-04\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 0s 655us/step - loss: 3.3956e-04 - val_loss: 3.3211e-04\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 0s 698us/step - loss: 3.3971e-04 - val_loss: 3.3045e-04\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 0s 669us/step - loss: 3.3908e-04 - val_loss: 3.3069e-04\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 0s 709us/step - loss: 3.3988e-04 - val_loss: 3.3225e-04\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 0s 655us/step - loss: 3.3894e-04 - val_loss: 3.3150e-04\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 0s 712us/step - loss: 3.3980e-04 - val_loss: 3.3231e-04\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 0s 678us/step - loss: 3.3966e-04 - val_loss: 3.2993e-04\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 0s 674us/step - loss: 3.3982e-04 - val_loss: 3.3056e-04\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import SimpleRNN\n",
    "rnn_model = Sequential([\n",
    "    SimpleRNN(1, input_shape=[None, 1])\n",
    "])\n",
    "rnn_model.compile('adam', 'mse')\n",
    "rnn_history = rnn_model.fit(X_train, y_train, epochs=20, batch_size=50, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 2s 3ms/step - loss: 0.0127 - val_loss: 6.8133e-04\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 6.9274e-04 - val_loss: 6.6446e-04\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 6.7126e-04 - val_loss: 6.4515e-04\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 6.4136e-04 - val_loss: 6.1008e-04\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 6.1495e-04 - val_loss: 5.8381e-04\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.9597e-04 - val_loss: 5.5779e-04\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.7471e-04 - val_loss: 5.4097e-04\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.5081e-04 - val_loss: 5.3022e-04\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.3633e-04 - val_loss: 5.1647e-04\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.2427e-04 - val_loss: 5.1807e-04\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.0807e-04 - val_loss: 5.0253e-04\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 4.9470e-04 - val_loss: 4.7065e-04\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 4.9385e-04 - val_loss: 4.7126e-04\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 4.7518e-04 - val_loss: 4.6598e-04\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 4.6866e-04 - val_loss: 4.5645e-04\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 4.7222e-04 - val_loss: 4.4189e-04\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 4.5315e-04 - val_loss: 4.5941e-04\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 4.4861e-04 - val_loss: 4.8069e-04\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 4.4906e-04 - val_loss: 4.4203e-04\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 4.3671e-04 - val_loss: 4.1470e-04\n"
     ]
    }
   ],
   "source": [
    "deep_rnn_model = Sequential([\n",
    "    SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    SimpleRNN(20, return_sequences=True),\n",
    "    SimpleRNN(1)\n",
    "])\n",
    "deep_rnn_model.compile('adam', 'mse', )\n",
    "deep_rnn_history = deep_rnn_model.fit(X_train, y_train, epochs=20, batch_size=50, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "series_2 = generate_time_series(1, n_steps + 10)\n",
    "X_new, Y_new = series_2[:, :n_steps], series_2[:, n_steps:]\n",
    "X = X_new\n",
    "for step_ahead in range(10):\n",
    "    y_pred_one = deep_rnn_model.predict(X[:, step_ahead:])[:, np.newaxis, :]\n",
    "    X = np.concatenate([X, y_pred_one], axis=1)\n",
    "\n",
    "Y_pred = X[:, n_steps:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "140/140 [==============================] - 2s 3ms/step - loss: 0.0523 - val_loss: 7.7429e-04\n",
      "Epoch 2/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 7.2238e-04 - val_loss: 6.9923e-04\n",
      "Epoch 3/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 7.0410e-04 - val_loss: 6.7808e-04\n",
      "Epoch 4/20\n",
      "140/140 [==============================] - 0s 2ms/step - loss: 6.8801e-04 - val_loss: 6.5904e-04\n",
      "Epoch 5/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 6.7161e-04 - val_loss: 6.4392e-04\n",
      "Epoch 6/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 6.5610e-04 - val_loss: 6.2887e-04\n",
      "Epoch 7/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 6.4335e-04 - val_loss: 6.1257e-04\n",
      "Epoch 8/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 6.2624e-04 - val_loss: 6.1967e-04\n",
      "Epoch 9/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 6.1006e-04 - val_loss: 5.8406e-04\n",
      "Epoch 10/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.9866e-04 - val_loss: 5.7883e-04\n",
      "Epoch 11/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.8886e-04 - val_loss: 5.7351e-04\n",
      "Epoch 12/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.7601e-04 - val_loss: 5.5459e-04\n",
      "Epoch 13/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.6137e-04 - val_loss: 5.3618e-04\n",
      "Epoch 14/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.5217e-04 - val_loss: 5.2581e-04\n",
      "Epoch 15/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.3975e-04 - val_loss: 5.3901e-04\n",
      "Epoch 16/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.3981e-04 - val_loss: 5.2753e-04\n",
      "Epoch 17/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.2367e-04 - val_loss: 5.0214e-04\n",
      "Epoch 18/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.1418e-04 - val_loss: 5.0242e-04\n",
      "Epoch 19/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 5.0763e-04 - val_loss: 4.9001e-04\n",
      "Epoch 20/20\n",
      "140/140 [==============================] - 0s 1ms/step - loss: 4.9959e-04 - val_loss: 4.8052e-04\n"
     ]
    }
   ],
   "source": [
    "deep_rnn_model_2 = Sequential([\n",
    "    SimpleRNN(20, return_sequences=True, input_shape=[None, 1]),\n",
    "    SimpleRNN(20, return_sequences=True),\n",
    "    SimpleRNN(10)\n",
    "])\n",
    "deep_rnn_model_2.compile('adam', 'mse', )\n",
    "deep_rnn_history = deep_rnn_model_2.fit(X_train, y_train, epochs=20, batch_size=50, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 347, in compute_output_shape\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_6\" \"                 f\"(type Sequential).\n    \n    One of the dimensions in the output is <= 0 due to downsampling in conv1d_2. Consider increasing the input size. Received input shape [50, 1, 1] which would produce output shape with a zero or negative value in a dimension.\n    \n    Call arguments received by layer \"sequential_6\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(50, 1, 1), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      3\u001b[0m conv_model \u001b[39m=\u001b[39m Sequential([\n\u001b[0;32m      4\u001b[0m     Conv1D(filters\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m ,kernel_size\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, strides\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m      5\u001b[0m     GRU(\u001b[39m20\u001b[39m, return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      6\u001b[0m     GRU(\u001b[39m20\u001b[39m, return_sequences\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      7\u001b[0m     TimeDistributed(Dense(\u001b[39m10\u001b[39m))\n\u001b[0;32m      8\u001b[0m ])\n\u001b[0;32m      9\u001b[0m conv_model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m conv_history \u001b[39m=\u001b[39m conv_model\u001b[39m.\u001b[39;49mfit(X_train, y_train[:, \u001b[39m3\u001b[39;49m::\u001b[39m2\u001b[39;49m], epochs\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file4gdereai.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\training.py\", line 993, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py\", line 347, in compute_output_shape\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer \"sequential_6\" \"                 f\"(type Sequential).\n    \n    One of the dimensions in the output is <= 0 due to downsampling in conv1d_2. Consider increasing the input size. Received input shape [50, 1, 1] which would produce output shape with a zero or negative value in a dimension.\n    \n    Call arguments received by layer \"sequential_6\" \"                 f\"(type Sequential):\n      • inputs=tf.Tensor(shape=(50, 1, 1), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv1D, GRU, TimeDistributed, Dense\n",
    "\n",
    "conv_model = Sequential([\n",
    "    Conv1D(filters=20 ,kernel_size=4, strides=2, padding='valid'),\n",
    "    GRU(20, return_sequences=True),\n",
    "    GRU(20, return_sequences=True),\n",
    "    TimeDistributed(Dense(10))\n",
    "])\n",
    "conv_model.compile(loss='mse', optimizer='adam')\n",
    "conv_history = conv_model.fit(X_train, y_train[:, 3::2], epochs=20, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv1d_5\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m model\u001b[39m.\u001b[39madd(InputLayer(input_shape\u001b[39m=\u001b[39m[\u001b[39mNone\u001b[39;00m, \u001b[39m1\u001b[39m]))\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m rate \u001b[39min\u001b[39;00m (\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m4\u001b[39m, \u001b[39m8\u001b[39m) \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m----> 6\u001b[0m     model\u001b[39m.\u001b[39;49madd(Conv1D(filters\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, kernel_size\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcausal\u001b[39;49m\u001b[39m'\u001b[39;49m, activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mrelu\u001b[39;49m\u001b[39m'\u001b[39;49m, dilation_rate\u001b[39m=\u001b[39;49mrate))\n\u001b[0;32m      7\u001b[0m model\u001b[39m.\u001b[39madd(Conv1D(filters\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, kernel_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m      8\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,)\n",
      "File \u001b[1;32mc:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\D568\\Anaconda3\\envs\\ml\\lib\\site-packages\\keras\\engine\\input_spec.py:250\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    248\u001b[0m     ndim \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape\u001b[39m.\u001b[39mrank\n\u001b[0;32m    249\u001b[0m     \u001b[39mif\u001b[39;00m ndim \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m ndim \u001b[39m<\u001b[39m spec\u001b[39m.\u001b[39mmin_ndim:\n\u001b[1;32m--> 250\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    251\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    252\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mis incompatible with the layer: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mexpected min_ndim=\u001b[39m\u001b[39m{\u001b[39;00mspec\u001b[39m.\u001b[39mmin_ndim\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    254\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfound ndim=\u001b[39m\u001b[39m{\u001b[39;00mndim\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    255\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFull shape received: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtuple\u001b[39m(shape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    256\u001b[0m         )\n\u001b[0;32m    257\u001b[0m \u001b[39m# Check dtype.\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"conv1d_5\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 1)"
     ]
    }
   ],
   "source": [
    "from keras.layers import InputLayer\n",
    "simpleWavenet = Sequential()\n",
    "model.add(InputLayer(input_shape=[None, 1]))\n",
    "\n",
    "for rate in (1, 2, 4, 8) * 2:\n",
    "    model.add(Conv1D(filters=20, kernel_size=2, padding='causal', activation='relu', dilation_rate=rate))\n",
    "model.add(Conv1D(filters=10, kernel_size=1))\n",
    "model.compile(loss='mse', optimizer='adam',)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_valid, y_valid))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d99db085c1b6fa038ba26401f1eed74618fe5233a12a797f9cf5f06f98ffca22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
